{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a973b94",
   "metadata": {},
   "source": [
    "数据源：mongodb170"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11ed71",
   "metadata": {},
   "source": [
    "## 用户信息 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "From LAC import LAC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient('mongodb://192.168.11.170:27017')['weibo']                              #连接mongodb170数据\n",
    "user_info = db['user'].find()                                                                    #获取用户信息的表格\n",
    "user_info = pd.DataFrame(user_info)                                                              #将获取到的表格转化为dataframe格式\n",
    "user_info\n",
    "# user = db['user'].find({}, {'_id': 1, 'fan_num': 1, 'follow_num': 1,'tweet_num': 1})\n",
    "# user = pd.DataFrame(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_o = user_info.drop(['crawl_at','crawl_at_timestamp','head_img_url','v'],\n",
    "                             axis=1,inplace=False)                                               #删除分析不需要的列\n",
    "user_info_o.rename(columns={'_id':'user_id'},inplace = True)                                     #重命名\n",
    "user_info_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_o.columns                                                                               #显示各列名（用户的所有属性）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e0b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_o.isna().sum()                                                                          #各列缺失值统计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8829478",
   "metadata": {},
   "source": [
    "除用户ID以及用户类型之外，其他十六组变量都存在缺失值；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa37550",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info = db['tweet_user'].find()\n",
    "tweet_info = pd.DataFrame(tweet_info)\n",
    "tweet_info                                                                                         #加载用户帖子的信息\n",
    "# user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b993161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_info['user_id'].unique())                                                                #68W帖子对应的用户数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_c = tweet_info.groupby('user_id').apply(lambda x: ''.join(x['content']+' '))                    #将每个用户发的所有帖子聚合到一起\n",
    "u_c = pd.DataFrame(u_c)\n",
    "u_c.columns = ['content']\n",
    "u_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b041d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_con = pd.merge(u_c,user_info_o,on='user_id',how = 'inner')                                      #将帖子和用户信息两个表格merge，通过相同列user_id\n",
    "pd_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_con.isna().sum()                                                                                 #合并后表格的缺失值统计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30e941",
   "metadata": {},
   "source": [
    "对于这2166条数据，个人简介、生日、标签、城市、受教育程度、认证信息、性取向、职业、情感状态存在缺失值；\n",
    "\n",
    "有2条数据粉丝数目，关注信息以及发微博数缺失，认定为异常值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70452ba8",
   "metadata": {},
   "source": [
    "### 文本清洗（Xu）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df,param1 = False,param2 = True):\n",
    "    \"\"\"\n",
    "    固定删除文本中的日期，时间，邮件地址，网址，“转发微博”，“显示地图”，“分享图片”\n",
    "    “XXX的微博视频”，含“谦毅”的帖子，选择删除表情，标签\n",
    "    :param df: dataframe, the content we need to clean is df['content']\n",
    "    :param param1: 是否删除文中的【】中的表情\n",
    "    :param param2: 是否删除文中#键间的文字\n",
    "    :return: 清洗过后的dataframe文本\n",
    "    \"\"\"\n",
    "    df = df.astype(str)                                                                           # 将所有元素转化为str类型\n",
    "    df['content'] = df['content'].str.replace(r\"\\d+/\\d+/\\d+|\", '') \\\n",
    "                                 .str.replace(\"【\",'').str.replace(\"】\",'')\\\n",
    "                                 .str.replace(r\"[0-2]?[0-9]:[0-6][0-9]\", '') \\\n",
    "                                 .str.replace(r\"[\\w]+@[\\.\\w]+\", '') \\\n",
    "                                 .str.replace(u\"@(.*?):|/@(.*) /\", '') \\\n",
    "                                 .str.replace(r\"([hH][tT]{2}[pP]://|[hH][tT]{2}[pP][sS]://|[wW]{3}.\"\n",
    "                                              r\"|[wW][aA][pP].|[fF][tT][pP].|[fF][iI][lL][eE].)[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]\",'')\\\n",
    "                                 .str.replace(u\"谦毅:(.*?)|/转发微博/g|/显示地图/g|/分享图片/g\",'')\\\n",
    "                                 .str.replace(u\"#\\S*?的微博视频|:\\S*?的微博视频\",'')\\\n",
    "                                 .str.replace(u'\\[.*?]|#| \\S*? 显示地图|转发微博|分享图片| \\S*?的微博视频|//@.*?:|@\\S*? |@\\S*?$','')\n",
    "\n",
    "    if param1:\n",
    "        df['content'] = df['content'].str.replace(u\"\\\\[.*?]\",'')                                    # 删除【】和【】中的表情\n",
    "    if param2:\n",
    "        df['content'] = df['content'].str.replace(u\"\\\\#.*?#\",'')                                    # 删除#号和#间的话题\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = clean_text(pd_con,param1 = True,param2 = True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631d1be",
   "metadata": {},
   "source": [
    "### 对聚合后的帖子进行分词以及词性标注 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e632a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lac_text_baidu(sentence,tag_list):\n",
    "    '''\n",
    "    词性标注并筛选（百度lac）\n",
    "    '''\n",
    "    stopwords = stopwordslist()\n",
    "#    lac.load_customization('mydict.txt')\n",
    "    lac_t = lac_lac.run(sentence)\n",
    "    data = {'word':lac_t[0],'tag':lac_t[1]}\n",
    "    df = pd.DataFrame(data)\n",
    "    df1 = df['word'].loc[df['tag'].isin(tag_list)]\n",
    "    outstr = []\n",
    "    for i in df1:\n",
    "        if i not in stopwords and len(i ) >1:\n",
    "            outstr.append(i)\n",
    "    return outstr\n",
    "\n",
    "def lac_seq_baidu(sentence):\n",
    "    stopwords = stopwordslist()\n",
    "    lac_t = lac_lac.run(sentence)\n",
    "    data = {'word':lac_t[0],'tag':lac_t[1]}\n",
    "    df = pd.DataFrame(data)\n",
    "    df1 = df['word']\n",
    "    outstr = []\n",
    "    for i in df1:\n",
    "        if i not in stopwords and len(i)>1:\n",
    "            outstr.append(i)\n",
    "    return outstr\n",
    "\n",
    "def stopwordslist():\n",
    "    '''\n",
    "    导入停词表文件\n",
    "    '''\n",
    "    stopwords = [line.strip() for line in open('停用词表全.txt',encoding='UTF-8').readlines()]\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b009d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['content'][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebdaea",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940969d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LAC import LAC\n",
    "lac_lac = LAC(mode='lac')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86fbd9c",
   "metadata": {},
   "source": [
    "- lac分词各个标签的含义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31038826",
   "metadata": {},
   "source": [
    "|标签\t|含义\t|标签\t|含义\t|标签\t|含义\t|标签\t|含义|\n",
    "|:---|:---|:---|:---|:---|:---|:---|:---|\n",
    "|n\t|普通名词\t|f\t|方位名词\t|s\t|处所名词\t|nw\t|作品名|\n",
    "|nz\t|其他专名\t|v\t|普通动词\t|vd\t|动副词\t|vn\t|名动词|\n",
    "|a\t|形容词\t|ad\t|副形词\t|an\t|名形词\t|d\t|副词|\n",
    "|m\t|数量词\t|q\t|量词\t|r\t|代词\t|p\t|介词|\n",
    "|c\t|连词\t|u\t|助词\t|xc\t|其他虚词\t|w\t|标点符号|\n",
    "|PER\t|人名\t|LOC\t|地名\t|ORG\t|机构名\t|TIME\t|时间|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2dfa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "df2['content_seq'] = df2['content'].apply(lambda x:lac_seq_baidu(x))                                 #lac分词结果  \n",
    "df2['content_select']  = df2['content'].apply(lambda x:lac_text_baidu(x,['n','nz','vn',\n",
    "                                                                         's','LOC','PER','ORG']))     #lac分词结果筛选，去除停用词\n",
    "'''\n",
    "筛选出名词、其他专名、名动词、处所名词、地名、人名、机构名\n",
    "'''\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cacc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2                                                                                     #添加分词结果后的表格"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c0766",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('发帖用户.csv')                                                             #将df2输出到csv，再转化为Excel文件，对数据有个直观的概览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e32ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[['user_id','content_seq','content_select']]\n",
    "df3                                                                                    #表格df3为user_id及对应的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['content_select'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d863f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(len(df3)):\n",
    "    if len(df3['content_select'][i]) == 0:\n",
    "        a.append(i)                                                                    #识别帖子内容为空的用户对应的index\n",
    "df4 = df3.drop(labels=None,axis=0,index=a)                                            #删除帖子内容为空的用户 默认inplace=false\n",
    "df4.reset_index(drop=True)                                                            #重新排列索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('用户帖子分词.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
